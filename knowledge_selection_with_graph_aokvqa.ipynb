{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f36ca3b-9527-4a69-a786-28bcd0d71d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from ruamel.yaml import YAML\n",
    "from pathlib import Path\n",
    "import utils\n",
    "import json\n",
    "from vqaTools.vqa import VQA\n",
    "import datetime\n",
    "import csv\n",
    "from dataset.utils import vqa_eval, save_result, load_json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4927b107-3d84-4a8d-893b-852bc50c4ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from accelerate import init_empty_weights, dispatch_model, infer_auto_device_map, load_checkpoint_and_dispatch\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from huggingface_hub import snapshot_download\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27fc14c5-91f3-4ed5-9ff2-ac8a4c75bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(params, args):\n",
    "    params['min_answer_length'] = args.min_answer_length\n",
    "    params['max_answer_length'] = args.max_answer_length\n",
    "    params['model_selection'] = args.model_selection\n",
    "    params['dist_selection'] = args.dist_selection\n",
    "\n",
    "    params['dataset'] = args.dataset\n",
    "    params['split_seed'] = args.split_seed\n",
    "    params['num_sample'] = args.num_sample\n",
    "    params['output_dir'] = args.output_dir\n",
    "    params['test_server'] = args.test_server\n",
    "\n",
    "    params['num_caps_per_img'] = args.num_caps_per_img\n",
    "    params['num_question_per_img'] = args.num_question_per_img\n",
    "    params['caption_file'] = args.caption_file\n",
    "\n",
    "    params['question_file'] = args.question_file\n",
    "    params['question_ppl_file'] = args.question_ppl_file\n",
    "    params['ans_dict_file'] = args.ans_dict_file\n",
    "\n",
    "    params['question_type'] = args.question_type\n",
    "\n",
    "    params['random_question'] = args.random_question\n",
    "    params['result_tag'] = args.result_tag\n",
    "    params['evaluate_direct'] = args.evaluate_direct\n",
    "    params['resume'] = args.resume\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc2a9f9-f3e6-45d3-8fa2-6487f44cdc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cap_dic(caption_data):\n",
    "    cap = []\n",
    "    que_id = []\n",
    "    for i in caption_data:\n",
    "        que_id.append(i['question_id'])\n",
    "        if isinstance(i['caption'], list):\n",
    "            total_caption_list = []\n",
    "            for ctx_id, cap_ in enumerate(i['caption'][:100]):\n",
    "                total_caption_list.append((cap_.capitalize().strip()).rstrip()+\".\")\n",
    "            cap.append(total_caption_list)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "    caption_dict = dict(zip(que_id, cap))\n",
    "    return caption_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a72bab-f70d-4c51-9994-f5d1ae7d9f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ans_to_cap_dic(ans_to_cap_data):\n",
    "    que_id = []\n",
    "    ans_dicts = []\n",
    "\n",
    "    for i in ans_to_cap_data:\n",
    "        que_id.append(i['question_id'])\n",
    "        if 'ans_to_cap_dict' not in i.keys():\n",
    "            key = 'tag'\n",
    "        else:\n",
    "            key = 'ans_to_cap_dict'\n",
    "        if isinstance(i[key], dict):\n",
    "                ans_dicts.append(i[key])\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "    ans_to_cap_dicts = dict(zip(que_id, ans_dicts))\n",
    "    return ans_to_cap_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16e4982f-8520-4c69-9dc5-67251ab2e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generated_question_dic(question_data):\n",
    "    que_id = []\n",
    "    syn_question = []\n",
    "    syn_answer = []\n",
    "    que_id = []\n",
    "    ans_dicts = []\n",
    "\n",
    "    for i in question_data:\n",
    "        que_id.append(i['question_id'])\n",
    "        if isinstance(i['question'], list):\n",
    "            total_syn_question_list = []\n",
    "            for ctx_id, syn_question_ in enumerate(i['question']):\n",
    "                total_syn_question_list.append(syn_question_.capitalize().strip().rstrip())\n",
    "            syn_question.append(total_syn_question_list)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "        if isinstance(i['answer'], list):\n",
    "            total_syn_answer_list = []\n",
    "            for ctx_id, syn_answer_ in enumerate(i['answer']):\n",
    "                total_syn_answer_list.append(syn_answer_.capitalize().strip().rstrip())\n",
    "            syn_answer.append(total_syn_answer_list)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "    syn_question_dict = dict(zip(que_id, syn_question))\n",
    "    syn_answer_dict = dict(zip(que_id, syn_answer))\n",
    "\n",
    "    return syn_question_dict,syn_answer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0923f0-5682-496c-be88-d32531051251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7496081b-7183-4bb9-95ce-4e71b60bf93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f69cbfc-c10b-4d05-a6f9-4976e1b37718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"NCCL_ASYNC_ERROR_HANDLING\"] = \"1\" #this work together with dist barrier timeout\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--config', default='./configs/AOKVQA_caption.yaml')\n",
    "parser.add_argument('--caption_file', default='/home/mingyu/projects/Img2Prompt/caption_question_files/aokvqa_val_caption.json')\n",
    "parser.add_argument('--question_file', default='/home/mingyu/projects/Img2Prompt/caption_question_files/aokvqa_val_question.json')\n",
    "parser.add_argument('--question_ppl_file', default=None)\n",
    "parser.add_argument('--ans_dict_file', default='/home/mingyu/projects/Img2Prompt/caption_question_files/aokvqa_val_ans_to_cap_dict.json')\n",
    "parser.add_argument('--question_type', default='g_q', type=str)\n",
    "\n",
    "parser.add_argument('--output_dir', default='output/VQA_caption')\n",
    "parser.add_argument('--resume', action='store_true')\n",
    "\n",
    "parser.add_argument('--evaluate_direct', action='store_true')\n",
    "\n",
    "parser.add_argument('--evaluate', action='store_true')\n",
    "parser.add_argument('--vqa_eval', action='store_true')\n",
    "\n",
    "parser.add_argument('--device', default='cuda')\n",
    "parser.add_argument('--seed', default=42, type=int)\n",
    "parser.add_argument('--split_seed', default=0, type=int)\n",
    "parser.add_argument('--num_sample', default=16, type=int)\n",
    "parser.add_argument('--ensemble', default=1, type=int)\n",
    "parser.add_argument('--random_question', action='store_true')\n",
    "parser.add_argument('--test_server', action='store_true')\n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument('--model_selection', default='opt-6.7b', type=str)\n",
    "parser.add_argument('--dist_selection', default='hugging', type=str)\n",
    "parser.add_argument('--select_cap', action='store_true')\n",
    "\n",
    "parser.add_argument('--dataset', default='vqa_caption', type=str)\n",
    "parser.add_argument('--result_tag', default='', type=str)\n",
    "\n",
    "parser.add_argument('--batch_size_test', default=64, type=int)\n",
    "\n",
    "\n",
    "parser.add_argument('--num_caps_per_img', default=30, type=int)\n",
    "parser.add_argument('--num_question_per_img', default=30, type=int)\n",
    "\n",
    "parser.add_argument('--min_answer_length', default=1, type=int,\n",
    "                    help='min answer length during inference (generate); '\n",
    "                         'None  == self.model.config.min_length (0 for t0)')\n",
    "parser.add_argument('--max_answer_length', default=10, type=int,\n",
    "                    help='max answer length during inference (generate); '\n",
    "                         'None  == self.model.config.max_length (20 for t0)')\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81f8a6bd-bd87-4bae-a574-2a3faa68badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = YAML(typ='rt')\n",
    "\n",
    "config = yaml.load(open(args.config, 'r'))\n",
    "# config = yaml.load(open(args.config, 'r'), Loader=yaml.Loader)\n",
    "config = update(config, args)\n",
    "args.result_dir = os.path.join(args.output_dir, 'result')\n",
    "\n",
    "Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(args.result_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "yaml.dump(config, open(os.path.join(args.output_dir, 'config.yaml'), 'w'))\n",
    "logger, writer = utils.setup_default_logging(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559663bf-8ff5-4610-a31d-9c53296f9d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9547f0c6-1200-4618-8ffe-244be9173a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dataset ####\n",
    "print(\"Creating vqa datasets\")\n",
    "test_data = []\n",
    "for f in config['test_file']:\n",
    "    test_data = json.load(open(f, 'r'))\n",
    "\n",
    "caption_data = json.load(open(config['caption_file'], 'r'))\n",
    "quesID_to_cap_dict = create_cap_dic(caption_data)\n",
    "\n",
    "question_data = json.load(open(config['question_file'], 'r'))\n",
    "quesID_to_ques_data,syn_answer_dict = create_generated_question_dic(question_data)  # synthetic question, synthetic answer\n",
    "\n",
    "ans_dict_data = json.load(open(config['ans_dict_file'], 'r'))\n",
    "ans_to_cap_dicts = create_ans_to_cap_dic(ans_dict_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4543baaf-8136-4b5b-9b22-41b65717ed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['val_ann_path']:\n",
    "    vqa = VQA(config['val_ann_path'], config['val_ques_path'])\n",
    "\n",
    "\n",
    "result_filename = config['result_tag']+'_'+config['dataset']+'_'+config['model_selection']+'_'+config['dist_selection'] + 'caps'+str(config['num_caps_per_img']) +'_question'+ str(config['num_question_per_img'])+'_questiontype'+'_'+config['question_type']\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c1e116c-dc51-434f-b0d5-c2b3ce075c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_logger = utils.MetricLogger(delimiter=\"  \", logger=logger)\n",
    "header = 'Generate VQA test result:'\n",
    "print_freq = 1000\n",
    "result = []\n",
    "tested_quesId_dict = {}\n",
    "# print(result)\n",
    "for tested_dict in result:\n",
    "    # print(result)\n",
    "    if tested_dict['answer'] is not None:\n",
    "        tested_quesId_dict[tested_dict['question_id']] = 1\n",
    "# print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d37e53af-e7d3-4744-af8c-68f7353d8630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from huggingface_hub import snapshot_download, notebook_login\n",
    "import huggingface_hub\n",
    "import os\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1942cd98-d1ab-42d9-a56a-d2f876c1a84c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 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\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "\n",
    "# 모델 로드\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9203aa6b-be14-4625-944b-4eaf18aa25b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f10f21-4fd7-42e6-8eed-6f268dfcd3bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for n, per_test_data in enumerate(metric_logger.log_every(test_data, print_freq, header)):\n",
    "for n, per_test_data in enumerate(test_data):\n",
    "\n",
    "    # if n <= 1340: continue\n",
    "    # print(n)\n",
    "    # break\n",
    "    kb_score_dict = {}\n",
    "    question = per_test_data['question'].lower().strip()\n",
    "    question_id = per_test_data['question_id']\n",
    "    # print(question_id, question)\n",
    "    \n",
    "    selected_kb_list = []\n",
    "    \n",
    "    file_path = f\"./knowledge_files/aokvqa_pagerank_kb/{question_id}.json\"\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"File {file_path} exists.\")\n",
    "        continue\n",
    "    else:\n",
    "        # with open(f\"../cluster_generated_kb/{question_id}.json\", \"r\") as f:\n",
    "        with open(f\"/home/hsh/DKSVQA-main/knowledge_files/aokvqa_cluster_generated_kb/{question_id}.json\", \"r\") as f:\n",
    "            kb = json.load(f)\n",
    "\n",
    "        kb = list(set(kb))        \n",
    "        \n",
    "        question_embedding = model.encode(question, convert_to_tensor=True)\n",
    "        knowledge_embeddings = model.encode(kb, convert_to_tensor=True)\n",
    "        \n",
    "        cosine_scores = util.pytorch_cos_sim(question_embedding, knowledge_embeddings)\n",
    "        \n",
    "        G = nx.Graph()\n",
    "        \n",
    "        G.add_node(\"question\", label=question)  # 성능 잘 나왔을 때 이부분 question으로 적음\n",
    "        # Knowledge 문장 노드 및 엣지 추가 (유사도 임계값 설정)\n",
    "        threshold = 0.5  # 유사도 임계값 (0.25 / 0.5 / 0.75)\n",
    "        \n",
    "        for idx, sentence in enumerate(kb):\n",
    "            similarity = cosine_scores[0][idx].item()\n",
    "            if similarity >= threshold:\n",
    "                G.add_node(f\"Knowledge_{idx}\", label=sentence)\n",
    "                G.add_edge(\"Question\", f\"Knowledge_{idx}\", weight=similarity)\n",
    "                \n",
    "        for i in range(len(kb)):\n",
    "            for j in range(i + 1, len(kb)):\n",
    "                # 각 Knowledge 문장들 간의 유사도 계산\n",
    "                similarity = util.pytorch_cos_sim(knowledge_embeddings[i], knowledge_embeddings[j]).item()\n",
    "                if similarity >= threshold:  # 유사도 임계값 설정\n",
    "                    G.add_edge(f\"Knowledge_{i}\", f\"Knowledge_{j}\", weight=similarity)\n",
    "        \n",
    "        # connected_nodes = []  # Question과 연결된 Knowledge 문장 인덱스 저장\n",
    "        # for idx, sentence in enumerate(kb):\n",
    "        #     similarity = cosine_scores[0][idx].item()\n",
    "        #     if similarity >= threshold:\n",
    "        #         node_name = f\"Knowledge_{idx}\"\n",
    "        #         G.add_node(node_name, label=sentence)\n",
    "        #         G.add_edge(\"Question\", node_name, weight=similarity)\n",
    "        #         connected_nodes.append(idx)  # 연결된 노드 인덱스 저장\n",
    "\n",
    "        # # Step 4: Question과 연결된 Knowledge 문장들 간의 유사도 계산 및 엣지 추가\n",
    "        # for i in range(len(connected_nodes)):\n",
    "        #     for j in range(i + 1, len(connected_nodes)):\n",
    "        #         idx_i = connected_nodes[i]\n",
    "        #         idx_j = connected_nodes[j]\n",
    "        \n",
    "        #         # 연결된 Knowledge 문장들 간의 유사도 계산\n",
    "        #         similarity = util.pytorch_cos_sim(knowledge_embeddings[idx_i], knowledge_embeddings[idx_j]).item()\n",
    "        #         if similarity >= threshold:  # 임계값 이상인 경우에만 엣지 추가\n",
    "        #             G.add_edge(f\"Knowledge_{idx_i}\", f\"Knowledge_{idx_j}\", weight=similarity)\n",
    "        \n",
    "        # Step 5: Personalized PageRank 계산\n",
    "        # personalization = {node: 0 for node in G.nodes()}\n",
    "        # personalization[\"Question\"] = 1.0  # Question 노드에 높은 가중치 부여\n",
    "                \n",
    "        # pagerank_scores = nx.pagerank(\n",
    "        #     G, \n",
    "        #     alpha=0.85,  # damping factor\n",
    "        #     personalization=personalization,  # 개인화 가중치\n",
    "        #     weight='weight'  # 엣지의 가중치를 고려\n",
    "        # )\n",
    "        \n",
    "        # pagerank 및 중심성 계산\n",
    "        degree_centrality = nx.degree_centrality(G)\n",
    "        betweenness_centrality = nx.betweenness_centrality(G)\n",
    "        pagerank = nx.pagerank(G, alpha=0.85)\n",
    "        \n",
    "        # Step 5: 가장 중요한 Knowledge 문장 선택 (PageRank 기준)\n",
    "        sorted_pagerank = sorted(pagerank.items(), key=lambda x: x[1], reverse=True)\n",
    "        # sorted_pagerank = sorted(pagerank_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        \n",
    "        # 시각화 코드 (나중에 필요시 참고!) ============================================================================================\n",
    "        # print(\"=== 중요도 순으로 정렬된 문장들 (PageRank 기준) ===\")\n",
    "        # print(f'question: {question}')\n",
    "        # for node, score in sorted_pagerank:\n",
    "        #     if node.startswith(\"Knowledge\"):\n",
    "        #         idx = int(node.split(\"_\")[1])\n",
    "        #         print(f\"문장: {kb[idx]} | 점수: {score:.4f}\")\n",
    "        \n",
    "    \n",
    "        # # Step 6: 그래프 시각화\n",
    "        # plt.figure(figsize=(12, 8))\n",
    "        # pos = nx.spring_layout(G, seed=42)  # 그래프 레이아웃\n",
    "\n",
    "        # # 노드 라벨 추출\n",
    "        # labels = nx.get_node_attributes(G, 'label')\n",
    "\n",
    "        # # 노드와 엣지 시각화\n",
    "        # nx.draw(G, pos, with_labels=True, labels=labels, node_size=3000, node_color=\"skyblue\", font_size=10, font_color=\"black\")\n",
    "        # edge_labels = nx.get_edge_attributes(G, 'weight')\n",
    "        # nx.draw_networkx_edge_labels(G, pos, edge_labels={(u, v): f\"{d['weight']:.2f}\" for u, v, d in G.edges(data=True)})\n",
    "\n",
    "        # plt.title(\"Question-Knowledge Sentence Graph with Centrality\")\n",
    "        # plt.show()\n",
    "        # ==============================================================================================================================\n",
    "        \n",
    "        for node, score in sorted_pagerank:\n",
    "            if node.startswith(\"Knowledge\"):\n",
    "                idx = int(node.split(\"_\")[1]) # kb[idx]\n",
    "                selected_kb_list.append(kb[idx])\n",
    "        \n",
    "        # if len(selected_kb_list) != 3:\n",
    "        #     print(len(selected_kb_list))\n",
    "        \n",
    "        # with open(f\"../okvqa_selected_kb/{question_id}.json\", \"w\") as f:\n",
    "        with open(f\"./knowledge_files/aokvqa_pagerank_kb/{question_id}.json\", \"w\") as f:\n",
    "            json.dump(selected_kb_list, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img2llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
